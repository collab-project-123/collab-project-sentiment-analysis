{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2197944-4ae8-4af5-b323-b3672478bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/nqg_7mk14rbbl81k2fk3s2j00000gn/T/ipykernel_41458/2071766955.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model3.load_state_dict(torch.load('bert_stock_sentiment_model.pth', map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentimentAnalysisModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# loading all models first\n",
    "\n",
    "# Load the model company\n",
    "with open('xgboost_model_compVsnifty.pkl', 'rb') as f:\n",
    "    loaded_model1 = pickle.load(f)\n",
    "    \n",
    "# load nasdaq model\n",
    "with open('xgboost_model_niftyVsnasdaq.pkl', 'rb') as f:\n",
    "    loaded_model2 = pickle.load(f)\n",
    "\n",
    "# load bert model\n",
    "class SentimentAnalysisModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentimentAnalysisModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 1)  # Output size is 1\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        outputs = self.classifier(pooled_output)\n",
    "        return outputs\n",
    "\n",
    "# load the saved model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loaded_model3 = SentimentAnalysisModel()\n",
    "loaded_model3.load_state_dict(torch.load('bert_stock_sentiment_model.pth', map_location=device))\n",
    "loaded_model3.to(device)\n",
    "loaded_model3.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01530054-6b6e-4c28-a06f-b3e4cc85ab7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# company\n",
    "#change values as input comes\n",
    "X_test1_dict = {\n",
    "    'Infosys net profit': [1.6],\n",
    "    'Nifty change_profit': [-0.29],\n",
    "    'Nifty change_close': [1],\n",
    "    'TCS change_profit': [0],\n",
    "    'Infosys change_profit': [0.65],\n",
    "    'HCL change_profit': [1],\n",
    "    'Nifty change_sales': [1],\n",
    "    'TCS change_sales': [-0.12],\n",
    "    'Infosys change_sales': [-1],\n",
    "    'Last_close': [-1]\n",
    "}\n",
    "\n",
    "X_test1 = pd.DataFrame(X_test1_dict)\n",
    "\n",
    "y_pred1= loaded_model1.predict(X_test1)\n",
    "y_pred_proba1 = loaded_model1.predict_proba(X_test1)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab68b74-45e4-421a-8646-9bd2f5e4dc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nasdaq\n",
    "# change the values as the input comes.\n",
    "X_test2_dict = {\n",
    "    'nasdaq_close_percentage_change': [0.03],\n",
    "    'nifty_close_percentage_change': [1],\n",
    "    'nasdaq_open_percentage_change': [-0.45],\n",
    "    'nifty_open_percentage_change': [0.45],\n",
    "    'nasdaq_high_percentage_change': [-0.23],\n",
    "    'nifty_high_percentage_change': [0.56],\n",
    "    'nasdaq_low_percentage_change': [-0.01],\n",
    "    'nifty_low_percentage_change': [0]\n",
    "}\n",
    "\n",
    "X_test2 = pd.DataFrame(X_test2_dict)\n",
    "\n",
    "y_pred2 = loaded_model2.predict(X_test2)\n",
    "y_pred_proba2 = loaded_model2.predict_proba(X_test2)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fd932a3-78b5-4478-97a8-df73a3cc6350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of sentences prediction: [-1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# bert sentiment analysis\n",
    "\n",
    "# Assuming 'model' and 'tokenizer' are already defined and loaded as per your original code\n",
    "\n",
    "def prepare_input(texts):\n",
    "    # Check if the input is a list or a single string\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]  # Convert single string to a list\n",
    "\n",
    "    # Prepare the input data for each text in the list\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    for text in texts:\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        attention_masks.append(inputs['attention_mask'])\n",
    "\n",
    "    # Stack the inputs to create tensors for batch processing\n",
    "    input_ids = torch.cat(input_ids, dim=0).to(device)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
    "\n",
    "    # Make predictions for the entire batch\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model3(input_ids, attention_mask=attention_masks)\n",
    "\n",
    "    # Apply sigmoid activation and threshold to get predictions\n",
    "    threshold = 0.5\n",
    "    predictions = torch.sigmoid(outputs).squeeze().cpu().numpy()\n",
    "\n",
    "    # Use numpy.where to assign -1 for bad sentiment, 1 for good sentiment\n",
    "    sentiment_output = np.where(predictions > threshold, 1, -1)\n",
    "\n",
    "    return sentiment_output\n",
    "\n",
    "# This will be changed by the news extracted from website.\n",
    "text_2 = ['Nifty falls short of its targets by a lot','Once held by Quant MF, this small cap stock is up 20% and here is why','PNB stock slips 2.5% after QIP launched at discounted price']\n",
    "\n",
    "# Predict for a list of sentences\n",
    "list_pred = prepare_input(text_2)\n",
    "print(f\"List of sentences prediction: {list_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e198d4d-b9fb-41f7-b5ef-1bf4e90b6d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3= np.mean(list_pred)\n",
    "if(y_pred3<0):\n",
    "    y_pred3=0\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dab8706-561c-464e-af81-07ea93e43ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def weighted_voting(predictions, weights):\n",
    "    weighted_sum = sum(p * w for p, w in zip(predictions, weights))\n",
    "    return 1 if weighted_sum > 0.5 * sum(weights) else 0\n",
    "\n",
    "weights = [0.3, 0.4, 0.3]\n",
    "final_prediction = weighted_voting([y_pred1,y_pred2,y_pred3], weights)\n",
    "print(final_prediction)  # Output depends on the weighted sum\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
