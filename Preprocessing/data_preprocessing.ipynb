{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**nasdaq historical data**"
      ],
      "metadata": {
        "id": "vemAiEmAzdCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Upload the CSV file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming the file is uploaded successfully, you can access it using the file name.\n",
        "file_name = list(uploaded.keys())[0]  # Get the file name\n",
        "\n",
        "# Step 2: Read the CSV file\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# Step 3: Display the first 10 rows\n",
        "print(df.head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "f2370d3f-1e2d-4f1f-df98-cdd658522b78",
        "id": "ywBlfkzXPTwm"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3d898d25-76de-48bd-a336-17626088c860\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3d898d25-76de-48bd-a336-17626088c860\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving HistoricalData_1725024094933.csv to HistoricalData_1725024094933 (4).csv\n",
            "          Date  Close/Last      Open      High       Low\n",
            "0   08/29/2024    17516.43  17610.57  17789.21  17482.60\n",
            "1   08/28/2024    17556.03  17738.80  17759.94  17439.40\n",
            "2   08/27/2024    17754.82  17655.52  17789.72  17573.37\n",
            "3   08/26/2024    17725.76  17867.85  17909.09  17645.69\n",
            "4   08/23/2024    17877.79  17772.73  17941.27  17700.27\n",
            "5   08/22/2024    17619.35  17993.72  18017.69  17589.15\n",
            "6   08/21/2024    17918.99  17840.51  17963.07  17790.98\n",
            "7   08/20/2024    17816.94  17849.09  17932.53  17758.20\n",
            "8   08/19/2024    17876.77  17649.74  17877.44  17585.58\n",
            "9   08/16/2024    17631.72  17516.40  17674.65  17502.82\n",
            "10  08/15/2024    17594.50  17394.55  17602.72  17375.41\n",
            "11  08/14/2024    17192.60  17227.64  17260.73  17032.17\n",
            "12  08/13/2024    17187.61  16944.74  17192.79  16943.95\n",
            "13  08-12-2024    16780.61  16793.64  16895.79  16699.39\n",
            "14  08-09-2024    16745.30  16636.52  16789.22  16574.57\n",
            "15  08-08-2024    16660.02  16408.27  16694.25  16262.93\n",
            "16  08-07-2024    16195.81  16622.31  16709.81  16179.53\n",
            "17  08-06-2024    16366.85  16261.36  16620.31  16137.65\n",
            "18  08-05-2024    16200.08  15712.53  16453.46  15708.54\n",
            "19  08-02-2024    16776.16  16780.45  16920.63  16582.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install xlrd\n",
        "!pip install openpyxl\n"
      ],
      "metadata": {
        "id": "2g8pzy82MBAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing:\n",
        "Date Cleaning and Formatting: Removed the time component from datetime entries, ensuring that only the date was retained. This step helped standardize the 'Date' column to a consistent format.\n",
        "\n",
        "Handling Multiple Date Formats: Accounted for different date formats within the column, converting them into a uniform format ('%m/%d/%Y'). This ensures that all dates are consistent, making further analysis easier."
      ],
      "metadata": {
        "id": "2qo_ouE6PlQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Path to the Excel file\n",
        "file_path = '/content/HistoricalData_1725024094933.csv'\n",
        "updated_file_path = '/content/HistoricalData_NASDAQ_modified_file.csv'\n",
        "\n",
        "def convert_date(date):\n",
        "    # If the date is a datetime object, format it directly\n",
        "    if isinstance(date, datetime):\n",
        "        return date.strftime('%m/%d/%Y')\n",
        "    elif isinstance(date, str):\n",
        "        try:\n",
        "            # If the date is a string, try to parse and format it\n",
        "            return datetime.strptime(date, '%m-%d-%Y').strftime('%m/%d/%Y')\n",
        "        except ValueError:\n",
        "            try:\n",
        "                return datetime.strptime(date, '%m/%d/%Y').strftime('%m/%d/%Y')\n",
        "            except ValueError:\n",
        "                return date\n",
        "    else:\n",
        "        return date\n",
        "\n",
        "try:\n",
        "    # Read the Excel file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Apply the conversion function to the 'Date' column\n",
        "    df['Date'] = df['Date'].apply(convert_date)\n",
        "\n",
        "    # Save the updated DataFrame back to an Excel file\n",
        "    df.to_csv(updated_file_path, index=False)\n",
        "\n",
        "    print(f\"Dates converted and file saved to {updated_file_path}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file at {file_path} was not found.\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error processing the file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77ElaOROMPIM",
        "outputId": "0247bea4-0253-4f89-d8ac-43be39e1d788"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dates converted and file saved to /content/HistoricalData_NASDAQ_modified_file.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stock news preprocessing and Filtering the news related to the Nifty IT 50 Companies**"
      ],
      "metadata": {
        "id": "gSdeEp3h0LRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install regex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6rcp7kCDNIp",
        "outputId": "153a0dbb-d790-4c5e-e532-fc52adf99823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2024.5.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering the news of Nifty it 50 companies\n",
        "This code processes a CSV file containing stock news to identify and count mentions of Nifty IT 50 companies in the news descriptions. It uses:\n",
        "\n",
        "- **pandas**: For loading, manipulating, and saving CSV data.\n",
        "- **re (regex)**: For searching company names in news descriptions.\n",
        "- **collections.Counter**: For counting the occurrences of each company's mentions.\n",
        "\n",
        "The script creates a new column indicating which companies are mentioned in each news entry and outputs a summary of the total mentions per company.\n"
      ],
      "metadata": {
        "id": "LBlnXgvoxWf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Example company names list\n",
        "company_names = [\n",
        "    (\"tata consultancy services\", \"tcs\"),\n",
        "    (\"infosys\", \"infy\"),\n",
        "    (\"wipro technologies\", \"wipro\"),\n",
        "    (\"hcl technologies\", \"hcl\"),\n",
        "    (\"ltimindtree\", \"ltimindtree\"),\n",
        "    (\"tech mahindra\", \"techm\"),\n",
        "    (\"persistent systems\", \"psys\"),\n",
        "    (\"l&t technology services\", \"ltts\"),\n",
        "    (\"mphasis\", \"mphasis\"),\n",
        "    (\"coforge\", \"coforge\")\n",
        "]\n",
        "\n",
        "# Load your CSV file\n",
        "df = pd.read_csv('stock_news.csv')\n",
        "\n",
        "# Initialize a counter to count occurrences of each company\n",
        "company_count = Counter()\n",
        "\n",
        "# Function to search for company names in description and update counter\n",
        "def find_companies(description):\n",
        "    found_companies = []\n",
        "    for full_name, short_name in company_names:\n",
        "        if re.search(rf'\\b{re.escape(full_name)}\\b', description, re.IGNORECASE) or \\\n",
        "           re.search(rf'\\b{re.escape(short_name)}\\b', description, re.IGNORECASE):\n",
        "            found_companies.append(full_name)\n",
        "            company_count[full_name] += 1\n",
        "    return ', '.join(found_companies) if found_companies else ''\n",
        "\n",
        "# Apply the function to the 'Description' column and create a new 'Company' column\n",
        "df['Company'] = df['Description'].apply(find_companies)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "df.to_csv('filtered_news.csv', index=False)\n",
        "\n",
        "# Create a DataFrame from the company_count dictionary for the summary\n",
        "company_summary_df = pd.DataFrame(company_count.items(), columns=['Company', 'Count'])\n",
        "\n",
        "# Sort the summary DataFrame by count in descending order\n",
        "company_summary_df = company_summary_df.sort_values(by='Count', ascending=False)\n",
        "\n",
        "# Print the summary DataFrame\n",
        "print(company_summary_df)\n",
        "\n",
        "# Optionally, save the summary to a CSV file\n",
        "company_summary_df.to_csv('company_news_count.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q89DLbNTvOkr",
        "outputId": "de2e95f5-0854-499b-a7c3-05679f51a841"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Company  Count\n",
            "4              tech mahindra    198\n",
            "2                    infosys    157\n",
            "0           hcl technologies    156\n",
            "1         wipro technologies    138\n",
            "5                ltimindtree    114\n",
            "3  tata consultancy services     82\n",
            "6                    mphasis     28\n",
            "7    l&t technology services      9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating new csv file that have the news related to Nifty it 50 companies"
      ],
      "metadata": {
        "id": "OhUK_J0hl_A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your CSV file\n",
        "df = pd.read_csv('filtered_news.csv')\n",
        "\n",
        "# Remove rows with blank entries in the 'Company' column\n",
        "df_filtered = df.dropna(subset=['Company'])\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "df_filtered.to_csv('nifty_it_50_stock_news.csv', index=False)\n",
        "\n",
        "print(\"Filtered news with blank entries removed has been saved to 'filtered_news_no_blank.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPefYgLXiRFF",
        "outputId": "ebb227a7-a040-42df-f867-7a30673c950a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered news with blank entries removed has been saved to 'filtered_news_no_blank.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries: The script imports pandas for data manipulation and re for regex operations.\n",
        "\n",
        "Define Keywords: Two lists of keywords are defined: pos_words_to_search for positive sentiment and neg_words_to_search for negative sentiment. These words are associated with potential stock price increases or decreases.\n",
        "\n",
        "Compile Regex Patterns: Positive and negative word lists are compiled into regex patterns using re.compile() with word boundaries to ensure accurate matching.\n",
        "\n",
        "Label Sentiment: A custom function, label_sentiment, is applied to each row. It combines the Title and Description fields, converts them to lowercase, and checks for the presence of positive or negative keywords:\n",
        "\n",
        "If a positive keyword is found, it labels the news as 1 (positive).\n",
        "If a negative keyword is found, it labels the news as 0 (negative).\n",
        "If no keywords are found, it returns None (neutral or no match)."
      ],
      "metadata": {
        "id": "kfdWpqmu4msi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('nifty_it_50_stock_news.csv')\n",
        "\n",
        "# Define positive and negative words/phrases\n",
        "pos_words_to_search = [\n",
        "    r'jump', r'rise', r'up', r'soar', r'surge', r'leap', r'climb', r'increase', r'grow', r'boost',\n",
        "    r'rocket', r'skyrocket', r'advance', r'gain', r'improve', r'strengthen', r'bullish', r'remarkable',\n",
        "    r'outstanding', r'healthy', r'strong', r'optimistic', r'upward', r'exceeds', r'outperforms'\n",
        "]\n",
        "\n",
        "neg_words_to_search = [\n",
        "    r'plunge', r'drop', r'fall', r'decline', r'slump', r'slide', r'tumble', r'crash', r'collapse', r'plummet',\n",
        "    r'sink', r'downturn', r'decrease', r'reduction', r'loss', r'dip', r'retreat', r'reversal', r'setback',\n",
        "    r'weakness', r'volatility', r'uncertainty', r'risk', r'concerns', r'fears', r'worries', r'caution',\n",
        "    r'warning', r'alert', r'red flag', r'headwinds', r'challenges', r'obstacles', r'hurdles', r'unclear',\n",
        "    r'downward', r'bearish', r'negative', r'soft', r'weak', r'sluggish', r'stagnant', r'flat', r'lackluster',\n",
        "    r'disappointing', r'underwhelming', r'unimpressive', r'uninspiring', r'gloomy', r'bleak', r'recession',\n",
        "    r'contraction', r'slowdown', r'stagnation', r'depression', r'crisis', r'turmoil', r'instability',\n",
        "    r'depreciation', r'devaluation', r'write-down', r'impairment', r'losses', r'discount', r'hit', r'blow',\n",
        "    r'blowback', r'backlash', r'fallout', r'consequences', r'ramifications', r'implications', r'repercussions'\n",
        "]\n",
        "\n",
        "# Compile regex patterns for positive and negative words\n",
        "pos_pattern = re.compile(r'\\b(?:' + '|'.join(pos_words_to_search) + r')\\b', re.IGNORECASE)\n",
        "neg_pattern = re.compile(r'\\b(?:' + '|'.join(neg_words_to_search) + r')\\b', re.IGNORECASE)\n",
        "\n",
        "# Function to label sentiment based on Title and Description columns\n",
        "def label_sentiment(row):\n",
        "    text = f\"{row['Title']} {row['Description']}\".lower()\n",
        "    if pos_pattern.search(text):\n",
        "        return 1  # Positive\n",
        "    elif neg_pattern.search(text):\n",
        "        return 0  # Negative\n",
        "    else:\n",
        "        return None  # Neutral or no match\n",
        "\n",
        "# Apply the sentiment labeling function\n",
        "df['label'] = df.apply(label_sentiment, axis=1)\n",
        "\n",
        "# Save the labeled data to a new CSV file\n",
        "df.to_csv('nifty_it_50_stock_news_labeled.csv', index=False)\n",
        "\n",
        "# Display a sample of the labeled data\n",
        "print(df[['Title', 'Description', 'label']].head())\n",
        "\n",
        "# Show the count of each label\n",
        "print(df['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrMGJcDB1YNt",
        "outputId": "08da7da8-0b68-4334-e61a-bd86d2b50753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               Title  \\\n",
            "0  Nifty, Sensex plunge as all sectors slip in th...   \n",
            "1  Taking Stock: Market reacts to mixed macroecon...   \n",
            "2  Closing Bell: Nifty below 24,150, Sensex plung...   \n",
            "3  Stock Radar: Vodafone Idea, Orchid Pharma, JSW...   \n",
            "4  Taking Stock: Sensex, Nifty end flat amid Hind...   \n",
            "\n",
            "                                         Description  label  \n",
            "0  Titan Company, Apollo Hospitals, Dr Reddy's La...    0.0  \n",
            "1  Titan Company, Apollo Hospitals, Dr Reddy's La...    NaN  \n",
            "2  Titan Company, Apollo Hospitals, Dr Reddy's La...    NaN  \n",
            "3  NMDC, Housing & Urban Development Corporation,...    NaN  \n",
            "4  Hero MotoCorp, Axis Bank, ONGC, Infosys and JS...    0.0  \n",
            "label\n",
            "1.0    150\n",
            "0.0    124\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TCS and Infosys income sheet**"
      ],
      "metadata": {
        "id": "wkWST2u9xmCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the whitespaces and creating new csv file"
      ],
      "metadata": {
        "id": "qyKee3dtwYkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV file\n",
        "df = pd.read_csv('merged_output.csv')\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "# Remove trailing white spaces from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Verify the column names\n",
        "print(df.columns)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "df.to_csv('merged_output_updated.csv', index=False)\n",
        "\n",
        "# Download the updated CSV file\n",
        "# from google.colab import files\n",
        "# files.download('updated_file.csv')\n",
        "\n",
        "# Display the first row\n",
        "print(df.head(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2dYMW7IpCfz",
        "outputId": "2f3446fc-9558-46f9-8e4d-9799c62bc821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date ', 'series ', 'OPEN ', 'HIGH ', 'LOW ', 'PREV. CLOSE ', 'ltp ',\n",
            "       'close ', 'vwap ', '52W H ', '52W L ', 'VOLUME ', 'VALUE ',\n",
            "       'No of trades '],\n",
            "      dtype='object')\n",
            "Index(['Date', 'series', 'OPEN', 'HIGH', 'LOW', 'PREV. CLOSE', 'ltp', 'close',\n",
            "       'vwap', '52W H', '52W L', 'VOLUME', 'VALUE', 'No of trades'],\n",
            "      dtype='object')\n",
            "          Date series      OPEN      HIGH       LOW PREV. CLOSE       ltp  \\\n",
            "0  31-Dec-2020     EQ  2,900.00  2,905.00  2,845.00    2,909.30  2,864.95   \n",
            "\n",
            "      close      vwap     52W H     52W L     VOLUME               VALUE  \\\n",
            "0  2,862.75  2,874.36  2,952.00  1,506.05  40,40,956  11,61,51,70,401.55   \n",
            "\n",
            "  No of trades  \n",
            "0     1,30,170  \n"
          ]
        }
      ]
    }
  ]
}